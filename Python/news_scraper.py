import requests
from bs4 import BeautifulSoup
import urllib.parse

def analyze_sentiment(title):
    """
    ç°¡æ˜“æƒ…ç·’åˆ†æï¼šæ ¹æ“šæ¨™é¡Œé—œéµå­—çµ¦åˆ†
    """
    # 1. å®šç¾©é—œéµå­—åº«
    positive_keywords = [
        "ä¸Šæ¼²", "å¤§æ¼²", "é£†å‡", "çªç ´", "æ–°é«˜", "ç‰›å¸‚", "çœ‹å¥½", 
        "ç²åˆ©", "åå½ˆ", "åŠ å€‰", "æŠ„åº•", "å¢æŒ", "å¤šå–®", 
        "Bull", "Surge", "High", "Record", "Jump", "Gain", "Profit"
    ]

    negative_keywords = [
        "ä¸‹è·Œ", "å¤§è·Œ", "æš´è·Œ", "å´©ç›¤", "æ–°ä½", "ç†Šå¸‚", "çœ‹ç©º", 
        "è™§æ", "å›èª¿", "æ¸›å€‰", "æ‹‹å”®", "æ­»å‰", "ç©ºå–®",
        "Bear", "Drop", "Crash", "Low", "Loss", "Sell", "Plunge"
    ]

    score = 0
    title_lower = title.lower()

    for k in positive_keywords:
        if k.lower() in title_lower:
            score += 1
            
    for k in negative_keywords:
        if k.lower() in title_lower:
            score -= 1
            
    if score > 0: return "åˆ©å¤š ğŸ“ˆ"
    if score < 0: return "åˆ©ç©º ğŸ“‰"
    return "ä¸­ç«‹ ğŸ˜"

def fetch_google_news(keyword="Bitcoin", limit=10):
    """
    çˆ¬å– Google News RSS ä¸¦å›å‚³ List[Dict]
    """
    # æ ¹æ“šé—œéµå­—æ˜¯å¦æœ‰ä¸­æ–‡å­—å…ƒï¼Œæ±ºå®šæœå°‹èªè¨€
    is_chinese = any(u'\u4e00' <= c <= u'\u9fff' for c in keyword)
    
    if is_chinese:
        params = "hl=zh-TW&gl=TW&ceid=TW:zh-Hant"
    else:
        params = "hl=en-US&gl=US&ceid=US:en"
        
    # URL ç·¨ç¢¼é—œéµå­—
    encoded_keyword = urllib.parse.quote(keyword)
    rss_url = f"https://news.google.com/rss/search?q={encoded_keyword}&{params}"
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }

    news_list = []
    try:
        response = requests.get(rss_url, headers=headers, timeout=10)
        if response.status_code == 200:
            soup = BeautifulSoup(response.content, features="xml")
            items = soup.find_all("item")
            
            for item in items[:limit]:
                title = item.title.text
                link = item.link.text
                pub_date = item.pubDate.text
                
                # é€²è¡Œæƒ…ç·’åˆ†æ
                sentiment = analyze_sentiment(title)
                
                news_list.append({
                    "title": title,
                    "link": link,
                    "date": pub_date,
                    "sentiment": sentiment
                })
    except Exception as e:
        print(f"News Scraper Error: {e}")
        
    return news_list